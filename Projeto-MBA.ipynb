{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Machine Learning\n",
    "\n",
    "## 1. Case RH - Retenção de funcionários\n",
    "Objetivo:\n",
    "Criar um modelo que represente o *Job Satisfaction* de um profissional de TI a partir de características da compania e outros dados obtidos pela pesquisa. Utilize os dados da pesquisa de 2018 do Stackoverflow.\n",
    "\n",
    "## 2. Case Empresa de Anúncios - Previsão de salários\n",
    "\n",
    "Objetivo:\n",
    "Criar um modelo que represente o *Salary* de um profissional de TI a partir de características da compania e outras características dos funcionários utilizando os dados disponibilizados na pesquisa de 2017 do Stackoverflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passos:\n",
    "\n",
    "0. Carregar base de dados\n",
    "1.Seleção de features - Análise das Features / Construir base analítica\n",
    "  - remover linhas com missing\n",
    "  - codificar variáveis categóricas como fatores\n",
    "  - etc.\n",
    "2. Análise exploratória da Base:\n",
    "  - Histograma de Salários\n",
    "  - Histograma de satisfação - Quantos tem satisfação maior que 0.7 \n",
    "  - Correlações das features, \n",
    "  - etc.\n",
    "4. Traduzir o problema - buscar a melhor solução de negócio\n",
    "5. Selecionar e treinar o modelo \n",
    "  - Selecionar o modelo\n",
    "  - Definir X (features) e y (variável dependente)\n",
    "  - Normalizar as features (facultativo, mas melhora os resultados de predição)\n",
    "  - Separar modelos em treino e teste \n",
    "  -Treinar o modelo\n",
    "6. Retornar MSE para o modelo e distribuição real do seu y_teste e do seu y_pred (y preditos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_rows', 3500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "data = pd.read_csv(\"../survey_results_public.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRATAMENTO DA BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimino linhas que tenham nulos nas colunas Salário, JobSatisfaction, JobSeekingStatus e CarreerSatisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[~(data.Salary.isnull() | \n",
    "        data.JobSatisfaction.isnull() |\n",
    "        data.CareerSatisfaction.isnull())]\n",
    "nrow = data2.shape[0]\n",
    "print(\"# Linhas :\", nrow)\n",
    "print(\"# Colunas: \", data2.shape[1])\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleto linhas com HoursPerWeek >= 20 ( EmploymentStatus full-time ou part-time) \n",
    "(Supondo erro no preenchimento da survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[(data2.HoursPerWeek<20)]\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleto colunas que possuam mais de 5 mil missing (90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_columns = data2.columns[data2.isnull().sum() >5000]\n",
    "df = data2.drop(del_columns, axis = 1)\n",
    "del_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT DO NUMERO DE MISSING POR COLUNA:\n",
    "\n",
    "#print(\"data_tratada shape: \", df.shape)\n",
    "#print(\"total missing data\")\n",
    "#print()\n",
    "#for col in df.columns:\n",
    "#    print(col , df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleto algumas colunas que são irrelevantes, que ainda possuem alto valor de missing ou que só possuem um só tipo de resposta (ex: Professional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colunas irrelevantes\n",
    "df = df.drop(\"Respondent\", axis = 1)\n",
    "df = df.drop('PronounceGIF', axis = 1)\n",
    "df = df.drop('ClickyKeys', axis = 1)\n",
    "\n",
    "#Colunas com alto valor de Missing Data\n",
    "df = df.drop('HaveWorkedDatabase', axis =1)\n",
    "df = df.drop('WantWorkDatabase', axis =1)\n",
    "df = df.drop('HaveWorkedPlatform', axis =1)\n",
    "df = df.drop('WantWorkPlatform', axis =1)\n",
    "\n",
    "#Coluna com apenas uma só resposta\n",
    "df = df.drop(\"Professional\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformo as colunas com múltiplas respostas em dummies\n",
    "\n",
    "\n",
    "HaveWorkedLanguage, WantWorkLanguage, IDE, DeveloperType e ImportantBenefits, Gender, Race, StackOverflowDevices, MetricAssess, EducationTypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_lista(lista):\n",
    "    return list(map(str.strip,lista))\n",
    "\n",
    "def get_dummy_cols(df, column_string, prefix = \"uses\"):\n",
    "    df1 = df[column_string].str.split(';').dropna()\n",
    "    df1 = df1.apply(lambda x: strip_lista(x))\n",
    "    df2 = pd.get_dummies(df1.apply(pd.Series).stack()).sum(level=0)\n",
    "    df = df.drop(column_string, axis = 1)\n",
    "    df2.columns = [prefix +\"_\"+ x for x in df2.columns]     \n",
    "    result = pd.merge(df,df2,left_index=True,right_index=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "df = get_dummy_cols(df,'HaveWorkedLanguage', prefix ='Worked_with')\n",
    "df = get_dummy_cols(df,'WantWorkLanguage', prefix = 'Want_work')\n",
    "df = get_dummy_cols(df,'IDE' ,prefix = 'Uses')\n",
    "df = get_dummy_cols(df, \"DeveloperType\", prefix = \"DevType\")\n",
    "df = get_dummy_cols(df,'ImportantBenefits' ,prefix = 'IsImportantBenefit')\n",
    "df = get_dummy_cols(df,'Gender' ,prefix = 'Gender')\n",
    "df = get_dummy_cols(df, 'Race', prefix = \"Race\")\n",
    "df = get_dummy_cols(df, 'StackOverflowDevices', prefix = \"Uses_StackOverflow_in\")\n",
    "df = get_dummy_cols(df, 'MetricAssess', prefix = \"MetricAssess_\")\n",
    "df = get_dummy_cols(df, 'EducationTypes', prefix = \"Education\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIM DO PRE TRATAMENTO - Salvo a base pré tratada\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
